# -*- coding: utf-8 -*-
"""UASBro.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uWQx1Xak1A_ay5Bnps7fAc9PFlzcQN15

# **Nama  : Marshanda Putri Salsabila**
# **NIM   : A11.2022.14816**
# **Kelas : DS - 03**

# **Link  :aaaa**

# **1. DATA UNDERSTANDING & EDA**
"""

# Import Libraries

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import RandomForestClassifier

# Load Dataset

df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')

# Menampilkan 5 data teratas

df.head()

# Identifikasi Missing Value & Tipe Data

df.info()

# Menampilkan statistik deskriptif

df.describe()

# Identifikasi missing value
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')

missing_values = df.isnull().sum()
missing_percentage = (df.isnull().sum() / len(df)) * 100

missing_info = pd.DataFrame({
    'Missing Count': missing_values,
    'Missing Percentage': missing_percentage
})

missing_info = missing_info[missing_info['Missing Count'] > 0]

if not missing_info.empty:
    print("\nMissing Values (Count and Percentage):")
    print(missing_info)
else:
    print("No missing values found after processing TotalCharges.")

import matplotlib.pyplot as plt
import seaborn as sns

# Pastikan 'TotalCharges' sudah diubah ke numerik dan missing values teridentifikasi
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')

# Hitung missing values untuk SEMUA kolom
missing_values_all = df.isnull().sum()
missing_percentage_all = (df.isnull().sum() / len(df)) * 100

missing_info_all = pd.DataFrame({
    'Missing Count': missing_values_all,
    'Missing Percentage': missing_percentage_all
}).sort_values(by='Missing Percentage', ascending=False)

# --- BAGIAN VISUALISASI UNTUK SEMUA KOLOM ---
plt.figure(figsize=(12, 7))

# Membuat diagram batang untuk Missing Percentage dari SEMUA kolom
sns.barplot(x=missing_info_all.index, y=missing_info_all['Missing Percentage'], palette='viridis')

# Menambahkan judul dan label
plt.title('Persentase Missing Values Per Kolom (Semua Kolom)', fontsize=14)
plt.xlabel('Nama Kolom', fontsize=12)
plt.ylabel('Persentase (%)', fontsize=12)
plt.xticks(rotation=90) # Memutar nama kolom agar tidak tumpang tindih dan terbaca semua

# Menambahkan label angka di atas setiap batang
for i, p in enumerate(missing_info_all['Missing Percentage']):
    plt.text(i, p + 0.1, f'{p:.2f}%', ha='center', va='bottom')

plt.tight_layout()
plt.show()

# Cek distribusi target (Churn) untuk cek Imbalance

plt.figure(figsize=(6,4))
sns.countplot(x='Churn', data=df, palette='viridis')
plt.title('Distribusi Target (Churn)')
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Memilih kolom numerik untuk analisis korelasi
numeric_df = df.select_dtypes(include=['float64', 'int64'])

# Menghitung matriks korelasi
correlation_matrix = numeric_df.corr()

# Membuat heatmap korelasi
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Heatmap Korelasi Fitur Numerik')
plt.show()

"""Sebelumnya, kolom TotalCharges bertipe teks (object) karena adanya spasi kosong. Setelah menjalankan kode
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce'), kolom ini kemudian berubah menjadi tipe numerik. spasi kosong otomatis jadi Nan.

**Analisis**

Berdasarkan analisis korelasi pada fitur numerik, ditemukan bahwa tenure (lama berlangganan) memiliki hubungan positif yang sangat kuat dengan TotalCharges, yang menunjukkan bahwa akumulasi biaya meningkat sejalan dengan loyalitas waktu pelanggan. Sementara itu, MonthlyCharges juga berkontribusi signifikan terhadap total biaya, namun beban bulanan yang tinggi sering kali menjadi pemicu bagi pelanggan untuk berhenti berlangganan (churn). Identifikasi lebih lanjut menunjukkan bahwa jenis kontrak merupakan prediktor terkuat, di mana pelanggan dengan kontrak month-to-month memiliki risiko churn jauh lebih tinggi dibandingkan pelanggan dengan kontrak jangka panjang. Selain faktor finansial, ketiadaan layanan pendukung seperti Online Security dan Tech Support serta profil Senior Citizen juga teridentifikasi sebagai variabel yang memperbesar peluang pelanggan untuk meninggalkan layanan.

# **2. DIRECT MODELING**

## **PREPROCESSING DATA**
"""

# Handle missing values in TotalCharges by dropping rows

df_clean = df.dropna(subset=['TotalCharges']).copy()

# Menetapkan Fitur (X) dan Target (y)
# Target (y) adalah kolom Churn
# Fitur (X) adalah semua kolom kecuali kolom Churn dan customerID

X = df_clean.drop(['Churn', 'customerID'], axis=1)
y = df_clean['Churn']

# Menampilkan informasi dimensi data
print(f"Dimensi Fitur (X): {X.shape}")
print(f"Dimensi Target (y): {y.shape}")

# Train-Test Split (Membagi data latih dan uji)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Import Library lagi

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import StandardScaler

# Identifikasi kolom numerik dan kategorikal

numerical_cols = X_train.select_dtypes(include=['int64', 'float64']).columns
categorical_cols = X_train.select_dtypes(include=['object']).columns

# Buat preprocessor menggunakan ColumnTransformer
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_cols),
        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)
    ])

"""## **Model Konvensional: *K-Nearest Neighbors* (KNN)**"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.pipeline import Pipeline # Import Pipeline

# Inisialisasi model dengan parameter default
knn_direct = Pipeline(steps=[
    ('preprocessor', preprocessor), # Dibutuhkan agar data teks berubah jadi angka
    ('clf', KNeighborsClassifier())
])

# Melatih model secara langsung
knn_direct.fit(X_train, y_train)

# Prediksi dan Evaluasi
y_pred_knn = knn_direct.predict(X_test)
print("EVALUASI KNN (DIRECT)")
print(f"Accuracy: {accuracy_score(y_test, y_pred_knn):.4f}")
print(classification_report(y_test, y_pred_knn))

# Visualisasi Confusion Matrix
plt.figure(figsize=(4,3))
sns.heatmap(confusion_matrix(y_test, y_pred_knn), annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix: KNN (Direct)')
plt.show()

"""## **Model *Ensemble Bagging: Random Forest***"""

from sklearn.ensemble import RandomForestClassifier

# Inisialisasi model dengan parameter default
rf_direct = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('clf', RandomForestClassifier(random_state=42))
])

# Melatih model secara langsung
rf_direct.fit(X_train, y_train)

# Prediksi dan Evaluasi
y_pred_rf = rf_direct.predict(X_test)
print("EVALUASI RANDOM FOREST (DIRECT)")
print(f"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}")
print(classification_report(y_test, y_pred_rf))

# Visualisasi Confusion Matrix
plt.figure(figsize=(4,3))
sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Greens')
plt.title('Confusion Matrix: Random Forest (Direct)')
plt.show()

"""## **Model *Ensemble Voting*: Gabungan *(VotingClassifier)***

Menggabungkan beberapa model konvensional untuk membuat prediksi final berdasarkan suara terbanyak atau probabilitas rata-rata.
"""

from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC

# Menyiapkan model konvensional anggota dengan parameter default
clf_lr = LogisticRegression(max_iter=1000)
clf_svc = SVC(probability=True)
clf_knn = KNeighborsClassifier()

# Membuat Voting Classifier (tanpa tuning)
voting_clf = VotingClassifier(
    estimators=[('lr', clf_lr), ('svc', clf_svc), ('knn', clf_knn)],
    voting='soft'
)

# Inisialisasi dalam pipeline direct
voting_direct = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('clf', voting_clf)
])

# Melatih model secara langsung
voting_direct.fit(X_train, y_train)

# Prediksi dan Evaluasi
y_pred_voting = voting_direct.predict(X_test)
print("EVALUASI VOTING CLASSIFIER (DIRECT)")
print(f"Accuracy: {accuracy_score(y_test, y_pred_voting):.4f}")
print(classification_report(y_test, y_pred_voting))

# Visualisasi Confusion Matrix
plt.figure(figsize=(4,3))
sns.heatmap(confusion_matrix(y_test, y_pred_voting), annot=True, fmt='d', cmap='Purples')
plt.title('Confusion Matrix: Voting (Direct)')
plt.show()

"""**Analisis**

Berdasarkan analisis dan evaluasi dari ketiga model yang telah dilatih secara langsung didapatkan hasil sebagai berikut:

- **KNN** menunjukkan akurasi keseluruhan sebesar 75.48%. Meskipun memiliki
recall yang cukup baik untuk kelas 'No' (tidak churn), recall untuk kelas 'Yes' (churn) hanya sekitar 51%, menunjukkan keterbatasan dalam mengidentifikasi pelanggan yang akan churn.
- **Random Forest** sedikit lebih unggul dengan akurasi 77.75%. Model ini meningkatkan precision untuk kelas 'Yes' menjadi 61%, namun sedikit menurunkan recall kelas 'Yes' menjadi 46%, yang berarti lebih konservatif dalam memprediksi churn.
- **Voting Classifier**, yang menggabungkan beberapa model, menunjukkan kinerja terbaik di antara ketiganya dengan akurasi tertinggi sebesar 78.61%. Model ini juga mencapai precision (63%) dan f1-score (54%) tertinggi untuk kelas 'Yes' (churn), meskipun recall untuk kelas 'Yes' sedikit di bawah KNN, yaitu 48%.

Secara keseluruhan, Voting Classifier dapat dianggap sebagai model yang paling baik dalam tahap pemodelan langsung ini karena memberikan akurasi tertinggi dan keseimbangan yang lebih baik antara precision dan recall untuk kelas 'Yes' (churn), yang seringkali menjadi fokus utama dalam masalah prediksi churn. Namun, recall untuk prediksi churn masih relatif rendah pada semua model, yang artinya ada ruang untuk perbaikan lebih lanjut.

## **3. Modeling Dengan Preprocessing**

## **Preprocessing Data**
"""

# Cek Duplikasi

duplicate_count = df.duplicated().sum()
print(f"Jumlah data duplikat: {duplicate_count}")

# Cek Outlier pada Fitur Numerik
# Cek kolom tenure, MonthlyCharges, dan TotalCharges (setelah dikonversi)

df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
numeric_cols = ['tenure', 'MonthlyCharges', 'TotalCharges']

plt.figure(figsize=(15, 5))
for i, col in enumerate(numeric_cols):
    plt.subplot(1, 3, i+1)
    sns.boxplot(x=df[col], color='skyblue')
    plt.title(f'Boxplot {col}')

plt.tight_layout()
plt.show()

# Cek Duplikasi data

duplicate_count = df.duplicated().sum()
print(f"Jumlah data duplikat: {duplicate_count}")

# Penanganan Missing Value, Duplikasi, dan Outlier
# Mengonversi TotalCharges dan menghapus baris kosong
df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')
df_clean = df.dropna(subset=['TotalCharges']).drop_duplicates()

# Menetapkan X dan y (Menghapus customerID karena tidak relevan)
X = df_clean.drop(['Churn', 'customerID'], axis=1)
y = df_clean['Churn']

# Split data (80:20)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"Data bersih siap digunakan. Jumlah baris: {len(df_clean)}")

# Preprocessing pake pipeline

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer

# Identifikasi kolom
num_features = X.select_dtypes(include=['int64', 'float64']).columns
cat_features = X.select_dtypes(include=['object']).columns

# Buat mesin pemroses (Transformer)
preprocessor = ColumnTransformer(
    transformers=[
        ('num', Pipeline([('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())]), num_features),
        ('cat', Pipeline([('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore'))]), cat_features)
    ])

"""## ***K-Nearest Neighbors* (KNN)**"""

from sklearn.metrics import confusion_matrix

# Melatih dan Prediksi
knn_pre = Pipeline(steps=[('preprocessor', preprocessor), ('clf', KNeighborsClassifier())])
knn_pre.fit(X_train, y_train)
y_pred_knn = knn_pre.predict(X_test)

print("=== EVALUASI KNN (WITH PREPROCESSING) ===")
print(classification_report(y_test, y_pred_knn))

# Visualisasi Confusion Matrix
plt.figure(figsize=(4,3))
sns.heatmap(confusion_matrix(y_test, y_pred_knn), annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix: KNN (Preprocessed)')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""## ***Random Forest (Bagging)***"""

# Melatih dan Prediksi
rf_pre = Pipeline(steps=[('preprocessor', preprocessor), ('clf', RandomForestClassifier(random_state=42))])
rf_pre.fit(X_train, y_train)
y_pred_rf = rf_pre.predict(X_test)

print("=== EVALUASI RANDOM FOREST (WITH PREPROCESSING) ===")
print(classification_report(y_test, y_pred_rf))

# Visualisasi Confusion Matrix
plt.figure(figsize=(4,3))
sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Greens')
plt.title('Confusion Matrix: Random Forest (Preprocessed)')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""## ***Voting Classifier (Voting)***"""

# Melatih dan Prediksi
voting_clf = VotingClassifier(
    estimators=[
        ('lr', LogisticRegression(max_iter=1000)),
        ('svc', SVC(probability=True)),
        ('knn', KNeighborsClassifier())
    ],
    voting='soft'
)
voting_pre = Pipeline(steps=[('preprocessor', preprocessor), ('clf', voting_clf)])
voting_pre.fit(X_train, y_train)
y_pred_voting = voting_pre.predict(X_test)

print("=== EVALUASI VOTING CLASSIFIER (WITH PREPROCESSING) ===")
print(classification_report(y_test, y_pred_voting))

# Visualisasi Confusion Matrix
plt.figure(figsize=(4,3))
sns.heatmap(confusion_matrix(y_test, y_pred_voting), annot=True, fmt='d', cmap='Purples')
plt.title('Confusion Matrix: Voting (Preprocessed)')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

"""**Evaluasi**



m
ds

dd

# ***4. Hyperparameter Tuning***

## **Tuning Model Konvensional: KNN**

Mencari jumlah tetangga optimal agar model tidak terlalu sensitif terhadap data pencilan.
"""

from sklearn.model_selection import GridSearchCV

# Menyusun parameter grid (Ruang pencarian)
param_grid_knn = {
    'clf__n_neighbors': [3, 5, 7, 9, 11],
    'clf__weights': ['uniform', 'distance'],
    'clf__metric': ['euclidean', 'manhattan']
}

# Proses Hyperparameter Tuning menggunakan GridSearchCV
grid_knn = GridSearchCV(knn_pre, param_grid_knn, cv=5, scoring='accuracy', n_jobs=-1)
grid_knn.fit(X_train, y_train)

# Memperoleh BEST PARAMETERS dan BEST ESTIMATOR
best_params_knn = grid_knn.best_params_
best_knn_model = grid_knn.best_estimator_

# 4Menghasilkan model dengan KONFIGURASI OPTIMAL
# (best_knn_model sudah otomatis terlatih/retrained oleh GridSearchCV)
y_pred_knn_final = best_knn_model.predict(X_test)

# --- OUTPUT HASIL TUNING ---
print("="*50)
print("HASIL OPTIMASI MODEL: K-NEAREST NEIGHBORS")
print("="*50)
print(f"Poin 3 - Parameter Terbaik : {best_params_knn}")
print(f"Poin 3 - Skor Validasi (CV): {grid_knn.best_score_:.4f}")
print(f"Poin 4 - Akurasi Final     : {accuracy_score(y_test, y_pred_knn_final):.4f}")
print("-" * 50)
print("Laporan Klasifikasi Final:")
print(classification_report(y_test, y_pred_knn_final))

# Menyajikan Confusion Matrix Final
plt.figure(figsize=(4,3))
sns.heatmap(confusion_matrix(y_test, y_pred_knn_final), annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix Final: KNN (Tuned)')
plt.show()

"""## **Tuning Model *Ensemble Bagging: Random Forest***

Mengontrol kedalaman pohon agar tidak overfitting.
"""

param_grid_rf = {
    'clf__n_estimators': [100, 200, 300],
    'clf__max_features': ['sqrt', 'log2'], # 'auto' is deprecated in scikit-learn >= 1.2, use 'sqrt' instead
    'clf__max_depth': [10, 20, None],
    'clf__min_samples_split': [2, 5],
    'clf__min_samples_leaf': [1, 2]
}
print("param_grid_rf dictionary defined.")

# =========================================================
# UNIT KOMPETENSI 3: HYPERPARAMETER TUNING - RANDOM FOREST
# =========================================================

from sklearn.model_selection import GridSearchCV

# Menyusun parameter grid (Sudah Anda definisikan sebelumnya)
param_grid_rf = {
    'clf__n_estimators': [100, 200],
    'clf__max_depth': [10, 20, None],
    'clf__min_samples_split': [2, 5],
    'clf__criterion': ['gini', 'entropy']
}

# Proses Hyperparameter Tuning menggunakan GridSearchCV
grid_rf = GridSearchCV(rf_pre, param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)
grid_rf.fit(X_train, y_train)

# POIN 3: Memperoleh BEST PARAMETERS dan BEST ESTIMATOR
best_params_rf = grid_rf.best_params_
best_rf_model = grid_rf.best_estimator_

# Melatih kembali best estimator (Retraining)
# Secara teknis, best_rf_model sudah melalui proses refit otomatis pada seluruh X_train
y_pred_rf_final = best_rf_model.predict(X_test)

# --- OUTPUT HASIL TUNING  ---
print("="*50)
print("HASIL OPTIMASI MODEL: RANDOM FOREST")
print("="*50)
print(f"Poin 3 - Parameter Terbaik : {best_params_rf}")
print(f"Poin 3 - Skor Validasi (CV): {grid_rf.best_score_:.4f}")
print(f"Poin 4 - Akurasi Final     : {accuracy_score(y_test, y_pred_rf_final):.4f}")
print("-" * 50)
print("Laporan Klasifikasi Final:")
print(classification_report(y_test, y_pred_rf_final))

# Menyajikan Confusion Matrix Final
plt.figure(figsize=(4,3))
sns.heatmap(confusion_matrix(y_test, y_pred_rf_final), annot=True, fmt='d', cmap='Greens')
plt.title('Confusion Matrix Final: Random Forest (Tuned)')
plt.show()

"""## **Tuning Model *Ensemble Voting***"""

# =========================================================
# UNIT KOMPETENSI 3: HYPERPARAMETER TUNING - VOTING CLASSIFIER
# =========================================================

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import VotingClassifier

# Menyusun parameter untuk model-model anggota (Base Learners)
# Kita menggunakan parameter yang sudah dianggap optimal
clf_lr_optimal = LogisticRegression(C=1.0, solver='liblinear', max_iter=1000)
clf_rf_optimal = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)
clf_knn_optimal = best_knn_model.named_steps['clf'] # Mengambil clf KNN yang sudah di-tuning sebelumnya

# Membuat Voting Classifier (Metode Tuning: Ensemble Voting)
best_voting_clf = VotingClassifier(
    estimators=[
        ('lr', clf_lr_optimal),
        ('rf', clf_rf_optimal),
        ('knn', clf_knn_optimal)
    ],
    voting='soft' # Berdasarkan probabilitas rata-rata
)

# Memperoleh BEST ESTIMATOR (Model Gabungan Optimal)
# Memasukkan voting classifier ke dalam pipeline final
best_voting_model = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('clf', best_voting_clf)
])

# Melatih kembali (Retraining) Best Estimator pada Data Latih
best_voting_model.fit(X_train, y_train)

# --- OUTPUT HASIL MODEL FINAL ---
y_pred_voting_final = best_voting_model.predict(X_test)

print("="*50)
print("HASIL MODEL FINAL: ENSEMBLE VOTING OPTIMAL")
print("="*50)
print(f"Poin 3 - Komposisi Model : Logistic Regression, Random Forest, KNN")
print(f"Poin 4 - Akurasi Final   : {accuracy_score(y_test, y_pred_voting_final):.4f}")
print("-" * 50)
print("Laporan Klasifikasi Final:")
print(classification_report(y_test, y_pred_voting_final))

# Confusion Matrix Final
plt.figure(figsize=(4,3))
sns.heatmap(confusion_matrix(y_test, y_pred_voting_final), annot=True, fmt='d', cmap='Purples')
plt.title('Confusion Matrix Final: Voting (Tuned)')
plt.show()

# Membuat Tabel Perbandingan Final
summary_final = pd.DataFrame({
    'Model': ['K-Nearest Neighbors', 'Random Forest', 'Ensemble Voting'],
    'Accuracy (Tuned)': [0.7626, 0.7960, 0.7918],
    'F1-Score (Churn/Yes)': [0.55, 0.56, 0.57]
})

print("="*45)
print("TABEL PERBANDINGAN PERFORMA FINAL")
print("="*45)
print(summary_final.sort_values(by='Accuracy (Tuned)', ascending=False).to_string(index=False))

# Menetapkan model terbaik untuk dideploy
best_model_for_deploy = best_rf_model

print("Berdasarkan hasil evaluasi, Model RANDOM FOREST dipilih untuk tahap Deployment")
print("karena memiliki akurasi tertinggi sebesar 79.6%.")

import joblib

# Menyimpan model ke dalam file .pkl
joblib.dump(best_rf_model, 'model_churn_rf.pkl')

print("--- PROSES SELESAI ---")
print("1. Model telah disimpan dengan nama 'model_churn_rf.pkl'")
print("2. Silakan klik ikon FOLDER di sebelah kiri Colab")
print("3. Cari file tersebut, klik kanan, lalu pilih DOWNLOAD")